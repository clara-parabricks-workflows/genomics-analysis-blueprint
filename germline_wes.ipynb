{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Germline Analysis Blueprint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This blueprint shows how to run a standard Germline workflow on whole exome data from `fastq` to `vcf`. We will start by downloading the sample reads and a set of BWA-indexed reference files. Then we will align the reads to the reference using BWA-MEM and call the variant using DeepVariant. The diagram below outlines these steps. \n",
    "\n",
    "![fq2bam_diagram](images/pbworkflow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the exome samples, we will use a GPU accelerated software suite called [Parabricks](https://docs.nvidia.com/clara/parabricks/latest/index.html). It contains over 25 popular secondary analysis tools for manipulating DNA and RNA data, including tools for alignment (BWA, Giraffe, Minimap2, STAR, etc.), variant calling (DeepVariant, HaplotypeCaller, DeepSomatic, StarFusion, etc.), and post processing steps such as quality checks and gvcf processing. Each tool offers nearly identical output to the CPU versions, but with speedups of up to 100x. For the full list of tools, see the [documentation](https://docs.nvidia.com/clara/parabricks/latest/toolreference.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this blueprint, we are running inside the Parabricks 4.4.0 Docker container which can be found in the [NVIDIA GPU Container (NGC) Registry](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/containers/clara-parabricks). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set used in this lab is the whole exome sample NA12878 from the [NIH](https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data_indexes/NA12878/sequence.index.NA12878_Illumina_HiSeq_Exome_Garvan_fastq_09252015) sequenced on Illumina. The fastq files for this sample, as well as the HG38 reference files (already indexed) can be downloaded using the `download_data.sh` script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh scripts/download_data.sh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can take up to 15 minutes to download and organize the data into the correct structure for this blueprint. In the meantime, let's discuss the data being downloaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the script completes, the `data` directory should contain two `.fastq.gz` files as a `ref` folder containing all the reference files, and an empty `output` folder where the output files from this workflow will be stored.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "data\n",
    "├── NIST7035_TAAGGCGA_L001_R1_001.fastq.gz\n",
    "├── NIST7035_TAAGGCGA_L001_R2_001.fastq.gz\n",
    "├── output\n",
    "└── ref\n",
    "    ├── Homo_sapiens_assembly38.dict\n",
    "    ├── Homo_sapiens_assembly38.fasta\n",
    "    ├── Homo_sapiens_assembly38.fasta.amb\n",
    "    ├── Homo_sapiens_assembly38.fasta.ann\n",
    "    ├── Homo_sapiens_assembly38.fasta.bwt\n",
    "    ├── Homo_sapiens_assembly38.fasta.fai\n",
    "    ├── Homo_sapiens_assembly38.fasta.pac\n",
    "    ├── Homo_sapiens_assembly38.fasta.sa\n",
    "    ├── Homo_sapiens_assembly38.known_indels.vcf.gz\n",
    "    └── Homo_sapiens_assembly38.known_indels.vcf.gz.tbi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the data downloaded correctly by running `ls` on the `data` directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the reference files downloaded correctly by running `ls` on the `ref` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data/ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is downloaded and organized for downstream analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align the fastq files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the [Parabricks fq2bam](https://docs.nvidia.com/clara/parabricks/latest/documentation/tooldocs/man_fq2bam.html) tool to align our `.fastq` files to the reference. The code to do this is contained in the bash script located at `scripts/fq2bam.sh`. The following cell executes this code. It will take a few minutes to run, so kick it off now and read below about what the script is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh scripts/fq2bam.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parabricks fq2bam is a wrapper for [BWA-MEM](https://github.com/lh3/bwa) that is optimized to run on the GPU, providing up to 60x speedups compared to the CPU-only version. It will also sort the output and can be configured to mark duplicates and recalibrate base quality scores. Below is a diagram showing how the steps within fq2bam are connected. \n",
    "\n",
    "![fq2bam_diagram](images/fq2bam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how to run fq2bam by opening up `scripts/fq2bam.sh`. We have pasted the contents of this file below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```code\n",
    "#!/bin/bash \n",
    "\n",
    "REF=\"data/ref/Homo_sapiens_assembly38.fasta\"\n",
    "KNOWN_SITES=\"data/ref/Homo_sapiens_assembly38.known_indels.vcf.gz\"\n",
    "FASTQ_1=\"data/NIST7035_TAAGGCGA_L001_R1_001.fastq.gz\"\n",
    "FASTQ_2=\"data/NIST7035_TAAGGCGA_L001_R2_001.fastq.gz\"\n",
    "OUT_BAM=\"data/output/NIST7035_TAAGGCGA_L001_R1_001.bam\"\n",
    "OUT_RECAL=\"data/output/recal.txt\"\n",
    "\n",
    "pbrun fq2bam \\\n",
    "    --ref ${REF} \\\n",
    "    --in-fq ${FASTQ_1} ${FASTQ_2} \\\n",
    "    --knownSites ${KNOWN_SITES} \\\n",
    "    --out-bam ${OUT_BAM} \\\n",
    "    --out-recal-file ${OUT_RECAL} \\\n",
    "    --gpusort --gpuwrite \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beginning of this script defines paths to the files needed to run fq2bam. For this example we will provide a reference `.fasta`, known sites `.vcf`, and the two reads as `.fastq` files. We will also needs output paths for the resulting `.bam` containing the aligned reads and the `recal.txt` with the recalibration scores.  \n",
    "\n",
    "At the end of of this script is the run command. Every command in Parabricks starts with `pbrun` followed by the name of the tool to run and then any arguments. Most of the arguments are file inputs as defined above, however there are two boolean flags at the end that will improve the performance of the tool. \n",
    "\n",
    "The coordinate sorting step of alignment can be moved to the GPU by including `--gpusort`. The GPU can also help writing the output `.bam` file by enabling the `--gpuwrite` flag. \n",
    "\n",
    "In this example, we are running with a minimal set of arguments but there are dozens of extra options outlined in the [documentation](https://docs.nvidia.com/clara/parabricks/latest/documentation/tooldocs/man_fq2bam.html#fq2bam-reference). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cell executing fq2bam has finished running, we can look inside the `data/output` folder and see the that `.bam` file containing our aligned reads has been generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data/output | grep .bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run variant calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the [Parabricks DeepVariant](https://docs.nvidia.com/clara/parabricks/latest/documentation/tooldocs/man_deepvariant.html) tool to call variants on the `.bam` we generated using fq2bam.  The code to do this is contained in the bash script located at `scripts/deepvariant.sh`. The following cell executes this code. It will take around 10 minutes to run, so kick it off now and read below about what the script is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh scripts/deepvariant.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepVariant is a variant caller that uses a convolutional neural network (CNN) as opposed to bayesian statistics to discover variants. This method often performs better, especially on low frequency variants. It has the added benefit that it can be retrained to improve performance on any dataset. In this blueprint, we will use the [GPU optimized version of DeepVariant found in Parabricks](https://docs.nvidia.com/clara/parabricks/latest/documentation/tooldocs/man_deepvariant.html).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how to run fq2bam by opening up `scripts/deepvariant.sh`. We have pasted the contents of this file below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash \n",
    "\n",
    "REF=\"data/ref/Homo_sapiens_assembly38.fasta\"\n",
    "IN_BAM=\"data/output/NIST7035_TAAGGCGA_L001_R1_001.bam\"\n",
    "OUT_VCF=\"data/output/NIST7035_TAAGGCGA_L001_R1_001.vcf\"\n",
    "\n",
    "pbrun deepvariant \\\n",
    "    --ref ${REF} \\\n",
    "    --in-bam ${IN_BAM} \\\n",
    "    --out-variants ${OUT_VCF} \\\n",
    "    --use-wes-model \\\n",
    "    --run-parition \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the fq2bam script, the beginning of the script defines the file paths needed to run Parabricks DeepVariant. This time we only need the reference `.fasta`, the aligned reads `.bam` file generated by fq2bam in the previous section, and the path to the output `.vcf` to store the variants. \n",
    "\n",
    "At the end of the script is the run command. Just as before, it starts with `pbrun` but this time instead of `fq2bam` we are running `deepvariant` with a minimal set of arguments. The file inputs are familiar, but let's look into the additional flag at the end. \n",
    "\n",
    "DeepVariant is based on a CNN model. Different CNNs can be trained on different datasets. By default, Parabricks DeepVariant uses a model trained on whole genome (WGS) data, however in this blueprint we are using an exome and must therefore use a CNN trained on whole exome (WES) data. To do this, we use the `--use-wes-model` argument. \n",
    "\n",
    "For more information on all the flags, check out the [documentation](https://docs.nvidia.com/clara/parabricks/latest/documentation/tooldocs/man_deepvariant.html#deepvariant-reference). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the cell executing deepvariant has finished running, we can look inside the `data/output` folder and see the that `.vcf` file containing the variants has been generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data/output | grep .vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire end-to-end germline workflow has now been run using Parabricks in this notebook environment, from `.fastq` to `.vcf`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook serves as an introduction for how to use Parabricks. There are many other resources for more in-depth tutorials such as [Cloud Usage Guides](https://docs.nvidia.com/clara/parabricks/latest/tutorials/cloudguides.html) for getting Parabricks up and running on popular clouds such as AWS, GCP, and Azure. There is also a [GitHub repository](https://github.com/clara-parabricks-workflows) full of Parabricks workflows examples such as [WDL](https://github.com/clara-parabricks-workflows/parabricks-wdl) and [NextFlow](https://github.com/clara-parabricks-workflows/parabricks-nextflow) workflows and even a [notebook](https://github.com/clara-parabricks-workflows/deepvariant-retraining-notebook/blob/main/Retraining_DeepVariant.ipynb) showing how to train customer DeepVariant models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
